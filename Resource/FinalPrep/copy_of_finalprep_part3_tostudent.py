# -*- coding: utf-8 -*-
"""Copy of FinalPrep_Part3_ToStudent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s_6rXI8zhXqGjuyjN5USxKT8lWLN-ZLr

# Final Preparation Part3 (Language Model)
Objective: 


*   Lecture8: Dictionary
*   Lecture9: Nested Structure
Look at the file FinalExam3_LM
[Link to problem](https://docs.google.com/document/d/1yliw1he71QN_laxYi9x5zjv68jM-UNXh19ccDX7C29E/edit?usp=sharing)
"""

#############################################
# FUNCTIONS (FILL CODE IN THIS PART)
#############################################
def train_language_model(data):
  # Input:
  #    data: a list of sentences
  # Return:
  #    model: a dictionary which contains
  #           (1) unk: default value for unknown word
  #           (2) unigram: a dictionary of unigram counts
  #           (3) bigram: a dictionary of bigram counts
  model = dict()
  unigram = dict()
  bigram = dict()
  unk = 0

  # fill your code here
  counter = []
  word = []

  for i in data :
    x = i.split()
    for j in x :
      if j not in word :
        word.append(j)
        counter.append(1)
      else : 
        counter[word.index(j)] += 1

  unk = round(1/len(word),5)

  for i in range(len(word)) :
    unigram[word[i]] = counter[i]
  
  for k in data :
    x = k.split()  
    for i in range(len(x)-1) :
      if (x[i],x[i+1]) not in dict.keys(bigram) :
        bigram[(x[i],x[i+1])] = 1
      else :
        bigram[(x[i],x[i+1])] += 1

  model['unk'] = unk
  model['unigram'] = unigram
  model['bigram'] = bigram
  return model

def compute_sentence(sentence, model):
  # Input:
  #    sentence: an input string to be calculated probability
  #    model: language model
  # Return:
  #    probability: probability of sentence to occur
  bigramprob = {}
  for i in dict.keys(model['bigram']) :
    bigramprob[i] = model['bigram'][i]/model['unigram'][i[0]]

  x = sentence.split()
  
  probability = 1
  if len(x) <= 1 :
    probability = model['unk']
  for i in range(len(x)-1) :
    if (x[i],x[i+1]) in dict.keys(bigramprob):
      probability *= bigramprob[(x[i],x[i+1])]
    else :
      probability *= model['unk']

  # probability =1 
  return probability

#############################################
# MAIN (DO NOT CHANGE THIS PART)
#############################################

# Step1: read data
data = ["<s> I am Sam </s>", "<s> Sam I am </s>", "<s> I am not Sam </s>"]

# Step2: train language model
model = train_language_model(data)
print('-', len(model['unigram']), 'vocabularies')
print('-', len(model['bigram']), 'word pairs')
print()

#############################################
# TEST CASES (DO NOT CHANGE THIS PART)
#############################################
i = 0
# Case1: The prob should be 0.14815
sentence = "<s> I am Sam </s>"
probability = compute_sentence(sentence, model)
print('Case1: Prob of',sentence, "=", round(probability,5))

# Case2: The prob should be 0.01235
sentence = "<s> I love Sam </s>"
probability = compute_sentence(sentence, model)
print('Case2: Prob of',sentence, "=", round(probability,5))

# Case3: The prob should be 0.16667
sentence = ""
probability = compute_sentence(sentence, model)
print('Case3: Prob of empty string =', round(probability,5))

# Case4: What is the prob?
sentence = "<s> I am not Sam </s>"
probability = compute_sentence(sentence, model)
print('Case4: Prob of',sentence, "=", round(probability,5))

# Case5: What is the prob?
sentence = "<s> Sam not I </s>"
probability = compute_sentence(sentence, model)
print('Case5: Prob of',sentence, "=", round(probability,5))

# Case6: What is the prob?
sentence = "<s>"
probability = compute_sentence(sentence, model)
print('Case6: Prob of',sentence, "=", round(probability,5))